{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VRKitchen: an Interactive 3D Virtual Environment for Task-oriented Learning\n",
    "\n",
    "[[PDF](https://arxiv.org/pdf/1903.05757.pdf) | [WEB](https://sites.google.com/view/vr-kitchen/)]\n",
    "\n",
    "## Table of Contents\n",
    "- [Abstarct](#abstract)\n",
    "- [1 Introduction](#1-introduection)\n",
    "- [3 VEKitchen Environment](#3-vrkitchen-environment)\n",
    "- [4 VR Chef Challenge](#4-vr-chef-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Integrated function:\n",
    "1. Enable embodied agents powered by modern AI methods (e.g., planning, re- inforcement learning, etc.) to perform complex tasks involving a wide range offine-grained object manipulations in a realistic environment.\n",
    "2. Allow human teachers to perform demonstrations to train agents (i.e., learning from demonstration)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "Interested task-oriented learning problems:\n",
    "1. Learning visual representation of a dynamic environment - an agent need to learn from physical interactions and reason over the underlying causality of object state changes.\n",
    "2. Learning to generate long-term plans for complex tasks - a complex task is often composed of various sub-tasks with sub-goals.\n",
    "3. Learning from human demonstrations to bootstrap agents' models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 VEKitchen Environment\n",
    "### 3.1 Architecture Overview\n",
    "![fig2](./fig/fig2.png)\n",
    "Figure 2: Architecture of VRKitchen. Users can either directly teleoperate the agent using VR device or send commands to the agent by Python API.\n",
    "\n",
    "### 3.3 User Interface\n",
    "![fig6](./fig/fig6.png)\n",
    "Figure 6: Users can provide demonstrations by doing tasks in VRKitchen. These data can be taken to initialize virtual agent's policy, which will be improved through interactions with the virtual environment.\n",
    "![fig7](./fig/fig7.png)\n",
    "Figure 7: Multi-modal data is available in the virtual environment. Figures in the first row show RGB, depth and semantic segmentations from a third person perspective. Figures in the second row are from the agent’s first person view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 VR Chef Challenge\n",
    "### 4.1 Tool to Use\n",
    "In each episode, the agent can control the translation and rotation of avatar’s right hand for 50 steps. The continuous action space is defined as a tuple $(∆x,∆y,∆z,∆φ,∆θ,∆ψ,γ)$, where &(x, y, z)& is the right hand 3D location and $(φ, θ, ψ)$ is the 3D rotation in terms of Euler angle. If the grab strength γ is bigger than a threshold (0.1 in our case), objects within a certain range of avatar's hand will be attached to a socket. Physics simulations are enabled on all the objects. For objects attached to agent's hand, physics simulation is disabled.\n",
    "\n",
    "### 4.2 Preparing Dishes\n",
    "#### 4.2.1 Atomic Actions\n",
    "Atomic actions and object affordance are defined in a following way:\n",
    "- Take {ingredient}: take an ingredient from a nearby receptacle;\n",
    "- Put into {receptacle}: put a held ingredient into a nearby receptacle;\n",
    "- Use {tool}: use a tool to change the state of a ingredient in a nearby receptacle;\n",
    "- Navigate {tool, receptacle}: move to a tool or receptacle;\n",
    "- Toggle {container}: change state of a container in front;\n",
    "- Turn: rotating the agent’s facing direction by 90 de- grees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
